# Anomaly Detection

异常检测工具库：PyOD(JMLR' 19)

## k-近邻

很直观的方法，计算每个点到第k个近邻的距离，设定阈值判断异常点

但看一眼就知道不太适合我们的场景

- 数据量大
- 可能会是一个高维的数据

## LOF

也相当直观，计算每个点在局部区域上的密度，计算其邻域点的密度，判断异常程度

同样也不适合我们的场景

- 数据量大
- 高维

## HBOS

Histogram-based Outlier Score

简单讲就是统计各个数据区域出现的频次，转化成出现概率

适合全局，不适合我们的场景

## COPOD

Copula-Based Outlier Detection

传统：把特征空间上的每个维度单独建模，估算一个样本在这个维度上的异常程度

此算法：通过一个copula函数（可以理解成将边缘分布不同的随机变量进行联合分布的建模的一种好用的工具），建模联合分布，估算“经验累积分布函数”）

经验累积分布函数：$F_n(x):=\frac{1}{n}\sum_{i=1}^n1\{X_i\leq x\}$

通过这个得到一个样本属于tail的概率

## Isolation Forest

孤立森林

不断对特征空间进行划分，异常点一般位于tree的上面（距离root更近）

（没办法分下去了）

## PCA

经典

但不适合我们的场景

## AutoEncoder

Encoder->Decoder，计算重建误差

## 后续模型合并

先没有看，说个大概

无监督异常检测通常会训练多个异常检测模型，再去合并

拿到新的数据集进行异常检测，如何选择最合适的异常检测模型->冷启动

